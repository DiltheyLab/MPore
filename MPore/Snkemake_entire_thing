import os
import pandas as pd

# Load environment variables
input_csv = os.getenv("INPUT_CSV")
output_dir = os.getenv("OUTPUT_DIR")
Dorado_path = os.getenv("DORADO_PATH")
user_motif_list_path = os.getenv("USER_MOTIF_LIST") 	
include_rebase_motifs = os.getenv("INCLUDE_REBASE_MOTIFS", "False").lower() == "true"
TSV_Enzyme = os.getenv("TSV_data")
TSV_REBASE = os.getenv("TSV_REBASE")
Split_Log=os.getenv("SPLIT")
REBASE_Motifs=os.getenv("REBASE_Motifs")
Heatmap=os.getenv("HEATMAP")
context=os.getenv("CONTEXT")
with open(user_motif_list_path, 'r') as file:
    user_motifs = [line.strip() for line in file if line.strip() and not line.strip().isdigit()]

data = pd.read_csv(input_csv)
input_base = os.path.splitext(os.path.basename(input_csv))[0]
updated_csv = os.path.join(output_dir, f"{input_base}_updated.csv")

bed_files = expand(os.path.join(output_dir, "{file_name}.bed"), file_name=data['File_name'].tolist())
bam_files = expand(os.path.join(output_dir, "{file_name}.bam"), file_name=data['File_name'].tolist())
sample_df_files = expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_6mA.csv"), file_name=data['File_name'].tolist())
sample_df_files_5mC = expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_5mC.csv"), file_name=data['File_name'].tolist())
sample_df_files_4mC = expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_4mC.csv"), file_name=data['File_name'].tolist())




wildcard_constraints:
    file_name = "|".join(data['File_name'])

rule all:
    input:
        updated_csv,
        expand(os.path.join(output_dir, "{file_name}"), file_name=data['File_name']),
        expand(os.path.join(output_dir, "{file_name}_blast_results.txt"), file_name=data['File_name']),
        os.path.join(output_dir, "Mtase_presence_e_25_values.xlsx"),
        os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        os.path.join(output_dir, "all_dorado_done.flag"),
        os.path.join(output_dir, "all_modkit_done.flag"),
        expand(os.path.join(output_dir, "Sample_DF_{file_name}_5mC.xlsx"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_{file_name}_5mC.csv"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_5mC.csv"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_{file_name}_6mA.xlsx"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_{file_name}_6mA.csv"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_6mA.csv"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_{file_name}_4mC.xlsx"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_{file_name}_4mC.csv"), file_name=data['File_name'].tolist()),
        expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_4mC.csv"), file_name=data['File_name'].tolist()),
        os.path.join(output_dir, "plots_5mC"),
        os.path.join(output_dir, "plots_6mA"),
        os.path.join(output_dir, "plots_4mC"),
        os.path.join(output_dir, "all_6mA_done.flag"),
        os.path.join(output_dir, "all_5mC_done.flag"),
        os.path.join(output_dir, "all_4mC_done.flag"),
        os.path.join(output_dir, 'Log_5mC_done.txt'),
        os.path.join(output_dir, "5mC_Regression_done.txt"),
        os.path.join(output_dir, "5mC_Plotting_done.txt"),
        os.path.join(output_dir, 'Log_6mA_done.txt'),
        os.path.join(output_dir, "6mA_Regression_done.txt"),
        os.path.join(output_dir, "6mA_Plotting_done.txt"),
        os.path.join(output_dir, 'Log_4mC_done.txt'),
        os.path.join(output_dir, "4mC_Regression_done.txt"),
        os.path.join(output_dir, "4mC_Plotting_done.txt"),
        os.path.join(output_dir, "Heatmap_Plotting_done.txt")
                       
rule run_python_script:
    input:
        input_csv
    output:
        updated_csv
    params:
        skip_update=False
    shell:
        """
        if [ "{params.skip_update}" = "True" ] && [ -e {output} ]; then
            echo "Skipping update as {output} already exists. If u want to update remove the flag skip_update";
        else
            python Skripts/Check_python_snaky.py {input} {output}
        fi
        """
rule run_prokka_analysis:
    conda:
        "environment.yaml"
    input:
        input_csv
    output:
        directory(os.path.join(output_dir, "{file_name}"))
    params:
        output_dir=output_dir,
        Ref_path=lambda wildcards: data[data['File_name'] == wildcards.file_name].iloc[0]['Reference_path'],
        proteins_db="./REBASE_proteins_goldset.fasta"
    shell:
        """
        prokka --outdir {output} --prefix {wildcards.file_name} --force --proteins {params.proteins_db} {params.Ref_path}
        """
rule run_blastp_analysis:
    conda:
        "environment.yaml"
    input:
        prokka_dir=os.path.join(output_dir, "{file_name}")
    output:
        os.path.join(output_dir, "{file_name}_blast_results.txt")
    params:
        BLAST_OUTDIR=output_dir
    shell:
        """
        blastp -query "{input.prokka_dir}/{wildcards.file_name}.faa" -db ./gold_standard_db -outfmt "6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore" -out {output}
        printf "Gene\tEnzyme\tpident\tlength\tmismatch\tgapopen\tqstart\tqend\tsstart\tsend\tevalue\tbitscore\n" | cat - {output} > temp && mv temp {output}
        """
rule run_create_Blast_Dataframe:
    conda:
        "environment.yaml"
    input:
        blast_results= expand(os.path.join(output_dir, "{file_name}_blast_results.txt"), file_name=data['File_name'].tolist())
    output:
        values_xlsx = os.path.join(output_dir, "Mtase_presence_e_25_values.xlsx"),
        mtase_file_path=os.path.join(output_dir, "Mtase_presence_e_25_values.csv")
    params:
        OUTDIR=output_dir
    shell:
        """
        Rscript ./Skripts/Create_Blast_DF.R  {params.OUTDIR}
        """
rule run_dorado:
    conda:
        "environment.yaml"
    input:
        csv_file=updated_csv,
        dorado_path=Dorado_path
    output:
        bam=os.path.join(output_dir, "{file_name}.bam"),
        sorted_bam=os.path.join(output_dir, "{file_name}_sorted.bam"),
        bai=os.path.join(output_dir, "{file_name}_sorted.bam.bai")
    params:
        reference_path=lambda wildcards: data[data['File_name'] == wildcards.file_name].iloc[0]['Reference_path'],
        pod5_path=lambda wildcards: data[data['File_name'] == wildcards.file_name].iloc[0]['pod5_path'],
        skip_dorado=False
    resources:
        dorado=1
    shell:
        """
        if [ -e {output.bam} ] && [ -e {output.sorted_bam} ] && [ -e {output.bai} ]; then
            echo "Skipping {wildcards.file_name} since BAM file already exists.";
        else
            PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:50 {input.dorado_path}/bin/dorado basecaller \
            --modified-bases-models {input.dorado_path}/lib/dna_r10.4.1_e8.2_400bps_hac@v5.0.0_4mC_5mC@v1,{input.dorado_path}/lib/dna_r10.4.1_e8.2_400bps_hac@v5.0.0_6mA@v1 \
            {input.dorado_path}/lib/dna_r10.4.1_e8.2_400bps_hac@v5.0.0 \
            {params.pod5_path} \
            --reference {params.reference_path} > {output.bam}

            samtools sort -o {output.sorted_bam} {output.bam}
            samtools index {output.sorted_bam}
        fi
        """
rule check_dorado_completion:
    input:
        bam_files
    output:
        flag=os.path.join(output_dir, "all_dorado_done.flag")
    shell:
        """
        all_files_exist=true
        for bam_file in {input}; do
            if [ ! -e $bam_file ]; then
                all_files_exist=false
                break
            fi
        done

        if [ "$all_files_exist" = true ]; then
            touch {output.flag}
        else
            echo "One or more BAM files are missing. Cannot mark Dorado as complete."
            exit 1
        fi
        """
rule run_modkit:
    conda:
        "environment.yaml"
    input:
        bam_files=rules.check_dorado_completion.output,
        csv_file=updated_csv
    output:
        os.path.join(output_dir, "{file_name}.bed")
    params:
        reference_path=lambda wildcards: data[data['File_name'] == wildcards.file_name].iloc[0]['Reference_path'],
        bam_path=lambda wildcards: pd.read_csv(updated_csv).loc[pd.read_csv(updated_csv)['File_name'] == wildcards.file_name, 'Bam_data'].iloc[0],
        skip_modkit=False
    shell:
        """
        if [ "{params.skip_modkit}" = "True" ]; then
            echo "Skipping {wildcards.file_name} due to skip_modkit flag."
            exit 0
        fi

        if [ -e {output[0]} ]; then
            echo "Skipping {wildcards.file_name} since the BED file already exists."
        else
            modkit pileup {params.bam_path} {output[0]} --ref {params.reference_path}
        fi
        """
rule check_modkit_completion:
    input:
        bed_files
    output:
        os.path.join(output_dir, "all_modkit_done.flag")
    shell:
        """
        all_files_exist=true
        for bed_file in {input}; do
            if [ ! -e $bed_file ]; then
                all_files_exist=false
                break
            fi
        done

        if [ "$all_files_exist" = true ]; then
            touch {output}
        else
            echo "One or more BED files are missing. Cannot mark Modkit as complete."
            exit 1
        fi
        """
rule run_6mA_analysis_script:
    conda:
        "environment.yaml"
    input:
        csv_list=rules.run_python_script.output,
        motif_list=user_motif_list_path,
        bed_files=bed_files,
        check=os.path.join(output_dir, "all_modkit_done.flag")
    output:
        os.path.join(output_dir, "Sample_DF_{file_name}_6mA.xlsx"),
        os.path.join(output_dir, "Sample_DF_{file_name}_6mA.csv"),
        os.path.join(output_dir, "Sample_DF_detailed_{file_name}_6mA.csv")
    params:
        output_dir=output_dir,
        mtase=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        tsv=TSV_Enzyme,
        RB_Motifs=REBASE_Motifs
    shell:
        """
        python Skripts/Run_analysis6mA.py {input.csv_list} {params.output_dir} {input.motif_list} {params.mtase} {params.tsv} {params.RB_Motifs}
        """

rule check_6mA_completion:
    input:
        sample_df_files  
    output:
        flag=os.path.join(output_dir, "all_6mA_done.flag")  # Flag file to indicate completion
    shell:
        """
        all_files_exist=true
        for sample_df_file in {input}; do
            if [ ! -e $sample_df_file ]; then
                all_files_exist=false
                break
            fi
        done

        if [ "$all_files_exist" = true ]; then
            touch {output.flag}  
        else
            echo "One or more Sample DF detailed files are missing. Cannot mark 6mA as complete."
            exit 1
        fi
        """

rule run_4mC_analysis_script:
    conda:
        "environment.yaml"
    input:
        csv_list=rules.run_python_script.output,
        motif_list=user_motif_list_path,
        bed_files=bed_files,
        check=os.path.join(output_dir, "all_6mA_done.flag")
    output:
        os.path.join(output_dir, "Sample_DF_{file_name}_4mC.xlsx"),
        os.path.join(output_dir, "Sample_DF_{file_name}_4mC.csv"),
        os.path.join(output_dir, "Sample_DF_detailed_{file_name}_4mC.csv")
    params:
        output_dir=output_dir,
        mtase=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        tsv=TSV_Enzyme,
        RB_Motifs=REBASE_Motifs
    shell:
        """
        python Skripts/Run_analysis4mC.py {input.csv_list} {params.output_dir} {input.motif_list} {params.mtase} {params.tsv} {params.RB_Motifs}
        """

rule check_4mC_completion:
    input:
        sample_df_files_4mC  
    output:
        flag=os.path.join(output_dir, "all_4mC_done.flag") 
    shell:
        """
        all_files_exist=true
        for sample_df_file in {input}; do
            if [ ! -e $sample_df_file ]; then
                all_files_exist=false
                break
            fi
        done

        if [ "$all_files_exist" = true ]; then
            touch {output.flag}  
        else
            echo "One or more Sample DF detailed files are missing. Cannot mark 6mA as complete."
            exit 1
        fi
        """

rule create_plots_dir:
    output:
        directory(os.path.join(output_dir, "plots_5mC")),
        directory(os.path.join(output_dir, "plots_6mA")),
        directory(os.path.join(output_dir, "plots_4mC"))
    shell:
        """
        mkdir -p {output[0]}
        mkdir -p {output[1]}
        mkdir -p {output[2]}
        """


rule run_5mC_analysis_script:
    conda:
        "environment.yaml"
    input:
        csv_list=rules.run_python_script.output,
        motif_list=user_motif_list_path,
        bed_files=bed_files,
        check=os.path.join(output_dir, "all_4mC_done.flag")
    output:
        os.path.join(output_dir, "Sample_DF_{file_name}_5mC.xlsx"),
        os.path.join(output_dir, "Sample_DF_{file_name}_5mC.csv"),
        os.path.join(output_dir, "Sample_DF_detailed_{file_name}_5mC.csv")
    params:
        output_dir=output_dir,
        mtase=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        tsv=TSV_Enzyme,
        RB_Motifs=REBASE_Motifs
    shell:
        """
        python Skripts/Run_analysis5mC.py {input.csv_list} {params.output_dir} {input.motif_list} {params.mtase} {params.tsv} {params.RB_Motifs}
        """

rule check_5mC_completion:
    input:
        sample_df_files_5mC  
    output:
        flag=os.path.join(output_dir, "all_5mC_done.flag")  # Flag file to indicate completion
    shell:
        """
        all_files_exist=true
        for sample_df_file in {input}; do
            if [ ! -e $sample_df_file ]; then
                all_files_exist=false
                break
            fi
        done

        if [ "$all_files_exist" = true ]; then
            touch {output.flag}  
        else
            echo "One or more Sample DF detailed files are missing. Cannot mark 5mC as complete."
            exit 1
        fi
        """

rule Refinement_log_5mC:
    conda:
        "environment.yaml"
    input:
        csv_list=input_csv,
        check=os.path.join(output_dir, "all_5mC_done.flag")
    output:
        os.path.join(output_dir, 'Log_5mC_done.txt')
    params:
        output_dir=output_dir,
        mtase_file=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        Log_analysis=config["Log_analysis"]
    shell:
        """
        if [ "{params.Log_analysis}" = "True" ]; then
            python ./Skripts/Workstation_last_feature_5mC.py {params.mtase_file} {params.output_dir} {params.output_dir} {input[0]};
            
            # Create the done.txt file to signal completion
            echo "Log_5mC_done" > {output}
        else
            echo "Skipping analysis as Log_analysis is False."
        fi
        """
rule run_5mC_Regression:
    conda:
        "environment.yaml"
    input:
        input_csv,
        Refinement_log=os.path.join(output_dir, 'Log_5mC_done.txt')
    output:
        os.path.join(output_dir, "5mC_Regression_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        tsv_rebase= TSV_REBASE,
        input_csv= input_csv,
        mtase=os.path.join(output_dir, "Mtase_presence_e_25_values.csv")
    shell:
        """
        Rscript ./Skripts/Loganalysis_5mC.R {params.OUTDIR} {params.OUTDIR} {params.tsv_rebase} {params.input_csv} {params.mtase}
        echo "Regression_5mC_done" > {output}
        """
rule run_5mC_Plotting:
    conda:
        "environment.yaml"
    input:
        input_csv,
        expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_5mC.csv"), file_name=data['File_name'].tolist()),
        Reg_done=os.path.join(output_dir, "5mC_Regression_done.txt")
    output:
        os.path.join(output_dir, "5mC_Plotting_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        tsv_enzyme=TSV_Enzyme,
        mtase_file=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        Plot_out=os.path.join(output_dir, "plots_5mC")
    shell:
        """
        python ./Skripts/5mC_Position_Plotting.py {params.mtase_file} {params.OUTDIR} {params.Plot_out} {input[0]}
        echo "Plotting_5mC_done" > {output}
        """
rule Refinement_log_6mA:
    conda:
        "environment.yaml"
    input:
        csv_list=input_csv,
        check=os.path.join(output_dir, "all_6mA_done.flag"),
        check_2=os.path.join(output_dir, "5mC_Plotting_done.txt")
    output:
        os.path.join(output_dir, 'Log_6mA_done.txt')
    params:
        output_dir=output_dir,
        mtase_file=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        Log_analysis=config["Log_analysis"]
    shell:
        """
        if [ "{params.Log_analysis}" = "True" ]; then
            python ./Skripts/Workstation_last_feature2.0.py {params.mtase_file} {params.output_dir} {params.output_dir} {input[0]};
            
            # Create the done.txt file to signal completion
            echo "Log_6mA_done" > {output}
        else
            echo "Skipping analysis as Log_analysis is False."
        fi
        """
rule run_6mA_Regression:
    conda:
        "environment.yaml"
    input:
        input_csv,
        Refinement_log=os.path.join(output_dir, 'Log_6mA_done.txt'),
        check_2=os.path.join(output_dir, "5mC_Plotting_done.txt")
    output:
        os.path.join(output_dir, "6mA_Regression_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        tsv_enzyme= TSV_REBASE,
        input_csv= input_csv,
        mtase=os.path.join(output_dir, "Mtase_presence_e_25_values.csv")
    shell:
        """
        Rscript ./Skripts/Loganalysis_6mA.R {params.OUTDIR} {params.OUTDIR} {params.tsv_enzyme} {params.input_csv} {params.mtase}
        echo "Regression_6mA_done" > {output}
        """
rule run_6mA_Plotting:
    conda:
        "environment.yaml"
    input:
        input_csv,
        expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_6mA.csv"), file_name=data['File_name'].tolist()),
        Reg_done=os.path.join(output_dir, "6mA_Regression_done.txt"),
        check_2=os.path.join(output_dir, "5mC_Plotting_done.txt")
    output:
        os.path.join(output_dir, "6mA_Plotting_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        tsv_enzyme=TSV_Enzyme,
        mtase_file=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        Plot_out=os.path.join(output_dir, "plots_6mA")
    shell:
        """
        python ./Skripts/6mA_Position_Plotting.py {params.mtase_file} {params.OUTDIR} {params.Plot_out} {input[0]}
        echo "Plotting_6mA_done" > {output}
        """
rule Refinement_log_4mC:
    conda:
        "environment.yaml"
    input:
        csv_list=input_csv,
        check=os.path.join(output_dir, "all_4mC_done.flag"),
        check2=os.path.join(output_dir, "6mA_Plotting_done.txt")
    output:
        os.path.join(output_dir, 'Log_4mC_done.txt')
    params:
        output_dir=output_dir,
        mtase_file=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        Log_analysis=config["Log_analysis"]
    shell:
        """
        if [ "{params.Log_analysis}" = "True" ]; then
            python ./Skripts/Workstation_last_feature_4mC.py {params.mtase_file} {params.output_dir} {params.output_dir} {input[0]};
            
            # Create the done.txt file to signal completion
            echo "Log_4mC_done" > {output}
        else
            echo "Skipping analysis as Log_analysis is False."
        fi
        """
rule run_4mC_Regression:
    conda:
        "environment.yaml"
    input:
        input_csv,
        Refinement_log=os.path.join(output_dir, 'Log_4mC_done.txt'),
        check2=os.path.join(output_dir, "6mA_Plotting_done.txt")
    output:
        os.path.join(output_dir, "4mC_Regression_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        tsv_enzyme= TSV_REBASE,
        input_csv= input_csv,
        mtase=os.path.join(output_dir, "Mtase_presence_e_25_values.csv")
    shell:
        """
        Rscript ./Skripts/Loganalysis_4mC.R {params.OUTDIR} {params.OUTDIR} {params.tsv_enzyme} {params.input_csv} {params.mtase}
        echo "Regression_4mC_done" > {output}
        """
rule run_4mC_Plotting:
    conda:
        "environment.yaml"
    input:
        input_csv,
        expand(os.path.join(output_dir, "Sample_DF_detailed_{file_name}_4mC.csv"), file_name=data['File_name'].tolist()),
        Reg_done=os.path.join(output_dir, "4mC_Regression_done.txt"),
        check2=os.path.join(output_dir, "6mA_Plotting_done.txt")
    output:
        os.path.join(output_dir, "4mC_Plotting_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        tsv_enzyme=TSV_Enzyme,
        mtase_file=os.path.join(output_dir, "Mtase_presence_e_25_values.csv"),
        Plot_out=os.path.join(output_dir, "plots_4mC")
    shell:
        """
        python ./Skripts/4mC_Position_Plotting.py {params.mtase_file} {params.OUTDIR} {params.Plot_out} {input[0]}
        echo "Plotting_4mC_done" > {output}
        """

rule Heatmap_Plotting:
    conda:
        "environment.yaml"
    input:
        Reg_done=os.path.join(output_dir, "4mC_Regression_done.txt"),
        Reg_done1=os.path.join(output_dir, "5mC_Regression_done.txt"),
        Reg_done2=os.path.join(output_dir, "6mA_Regression_done.txt"),
    output:
        os.path.join(output_dir, "Heatmap_Plotting_done.txt")
    params:
        OUTDIR= output_dir.strip(),
        Context= context,
        gene_file=os.path.join(output_dir, "All_Isolates_gene_loci.csv")
    shell:
        """
        if [ "$HEATMAP" = "TRUE" ]; then
            Rscript ./Skripts/Heatmap_Plots.R {params.OUTDIR} {params.Context} {params.gene_file}
            echo "Heatmap_plotting_done" > {output}
        else
            echo "Heatmap not set to TRUE, skipping plotting."
            echo "skipped" > {output}
        fi
        """



